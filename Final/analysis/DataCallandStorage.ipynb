{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHAT I HAVE DONE FOR DATA STORAGE\n",
    "\n",
    "- Calling crime database of boston through API paging through Data\n",
    "- There were two crime database of different time period:\n",
    "- 2012 to 2015 and 2015 to 2017\n",
    "- Two Database columns' name are different as Boston Gov. stored data in different format: Legacy and New\n",
    "- Renamed the similar columns of both and named them as same.\n",
    "- Combining database together based on common columns name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CALLING THROUGH API AND STORING RAW DATA TO LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "boston_api_key=os.getenv('BOSTON_API_KEY') #article_api_key=os.getenv('Article_Search_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calling data using Rest API and storing them in local machine\n",
    "\n",
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "def callnStoreData(url,recordRange,orderby): #\n",
    "    num = 0\n",
    "    for x in range(recordRange):\n",
    "        urlA = url+\"?\"+\"&$limit=10000\" + \"&$offset=\" + str(num) + \"&$order=\"+ orderby + \"&$$app_token=\" + boston_api_key\n",
    "        \n",
    "        #Data calling through API\n",
    "        \n",
    "        num=num+10000\n",
    "        response = requests.get(urlA)\n",
    "        if response.status_code == 200:   # indicates request has succeeded.\n",
    "            data = response.json()\n",
    "        else:\n",
    "            print('Request not accepted')\n",
    "            break\n",
    "\n",
    "        #Data store to local\n",
    "        \n",
    "        a=url.split('/')\n",
    "        b=a[4].split('?')\n",
    "        file_name=str(datetime.datetime.now())+'@'+b[0]\n",
    "        #print(file_name)\n",
    "        with open('../data/'+file_name, 'w') as outfile:  \n",
    "            json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first database in json file format\n",
    "\n",
    "#crime records from 2012 to 2015 (Legacy format)\n",
    "url1=\"https://data.cityofboston.gov/resource/ufcx-3fdn.json\"\n",
    "callnStoreData(url1,27,'fromdate')#270k records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#second database in json file format\n",
    "\n",
    "#crime records from 2015 to till date(new format)\n",
    "url2 =\"https://data.cityofboston.gov/resource/29yf-ye7n.json\"\n",
    "callnStoreData(url2,18,'occurred_on_date')#180K records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request not accepted\n"
     ]
    }
   ],
   "source": [
    "#third database in json file format\n",
    "\n",
    "#Boston Employee earning records of 2015\n",
    "url3 =\"https://data.cityofboston.gov/resource/bejm-5s9g.json\"\n",
    "callnStoreData(url3,3,'name')#25K records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#forth database in json file format\n",
    "\n",
    "#Boston Police Dept FIO records 2014 to Jan 2017 data\n",
    "url4 =\"https://data.cityofboston.gov/resource/2pem-965w.json\"\n",
    "callnStoreData(url4,16,'FIRST_INSERTTIME')#152K records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESSING THE RAW DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#accessing path where raw data are stored\n",
    "filePath = '../data/*.json'\n",
    "localfileDir=glob.glob(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coverting all json files of same database(2012-2015) into consolidated csv file\n",
    "df1=pd.DataFrame()\n",
    "for file in localfileDir:\n",
    "    if 'ufcx-3fdn' in  file:\n",
    "        with open(file) as f:\n",
    "            dfn1 = pd.DataFrame(json.load(f))\n",
    "            df1 = pd.concat([df1,dfn1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.to_csv(\"../data/ProcessedData/crime_data_2012_to_2015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coverting all json files of same database(2015-2017) into consolidated csv file\n",
    "df2=pd.DataFrame()\n",
    "for file in localfileDir:\n",
    "    if '29yf-ye7n' in  file:\n",
    "        with open(file) as f:\n",
    "            dfn2 = pd.DataFrame(json.load(f))\n",
    "            df2 = pd.concat([df2,dfn2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv(\"../data/ProcessedData/crime_data_2015_to_2017.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coverting all json files of employee database(2015) into consolidated csv file\n",
    "df3=pd.DataFrame()\n",
    "for file in localfileDir:\n",
    "    if 'bejm-5s9g' in  file:\n",
    "        with open(file) as f:\n",
    "            dfn3 = pd.DataFrame(json.load(f))\n",
    "            df3 = pd.concat([df3,dfn3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.to_csv(\"../data/ProcessedData/BostonEmployeeEarningof2015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coverting all json files of Boston Police Dept FIO database into consolidated csv file\n",
    "df4=pd.DataFrame()\n",
    "for file in localfileDir:\n",
    "    if '2pem-965w' in  file:\n",
    "        with open(file) as f:\n",
    "            dfn4 = pd.DataFrame(json.load(f))\n",
    "            df4 = pd.concat([df4,dfn4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.to_csv(\"../data/ProcessedData/BostonPoliceDepartmentFIO_2014_to_2017.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RENAMING & FILTERING REQUIRED COLUMNS BEFORE MERGING BOTH DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selecting columns from database1\n",
    "df11=df1.ix[:,('compnos','incident_type_description','reptdistrict','fromdate','shooting','year','month','day_week','streetname','location')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#renaming columns\n",
    "df11.columns=['INCIDENT_NUM','OFFENSE_DESCRIPTION','DISTRICT','OCCURRED_ON_DATE','SHOOTING','YEAR','MONTH','DAY_OF_WEEK','STREET','LOCATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selecting columns from database2\n",
    "df22=df2.ix[:,('incident_number','offense_description','district','shooting','occurred_on_date','year','month','day_of_week','street','location')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#renaming columns\n",
    "df22.columns=['INCIDENT_NUM','OFFENSE_DESCRIPTION','DISTRICT','SHOOTING','OCCURRED_ON_DATE','YEAR','MONTH','DAY_OF_WEEK','STREET','LOCATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rearranging columns\n",
    "df22=df22.ix[:,('INCIDENT_NUM','OFFENSE_DESCRIPTION','DISTRICT','OCCURRED_ON_DATE','SHOOTING','YEAR','MONTH','DAY_OF_WEEK','STREET','LOCATION')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merging two database\n",
    "df_final = pd.concat([df11,df22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#storing the final database to local as csv\n",
    "df_final.to_csv(\"/Users/rajusingh/Final/data/ProcessedData/merged_crime_data_2012_to_2017.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
